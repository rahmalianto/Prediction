{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IMPORT LIBRARY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv #csv operations\n",
    "import numpy as np #matrix operations\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPEN CSV FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dataset is publically available at* https://archive.ics.uci.edu/ml/datasets/Bank+Marketing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed', 'y']\n",
      "[39, 'services', 'single', 'high.school', 'no', 'no', 'no', 'telephone', 'may', 'fri', 346, 4, 999, 0, 'nonexistent', 1.1, 93.994, -36.4, 4.855, 5191.0, True]\n",
      "number of rows: 4120\n"
     ]
    }
   ],
   "source": [
    "with open('bank-additional/bank-additional.csv', 'r') as bank_csv:\n",
    "    bank_info = csv.reader(bank_csv, delimiter=';')\n",
    "    \n",
    "    header = next(bank_info)\n",
    "    \n",
    "    with open('noHeader_bank.csv', 'w', newline='') as noHeader_bank_info:\n",
    "        csv_writer = csv.writer(noHeader_bank_info, delimiter=';')\n",
    "        \n",
    "        data = []\n",
    "        for row in bank_info:\n",
    "            # determine variable data types\n",
    "            age = int(row[0])\n",
    "            job = row[1]\n",
    "            marital = row[2]\n",
    "            education = row[3]\n",
    "            default = row[4]\n",
    "            housing = row[5]\n",
    "            loan = row[6]\n",
    "            contact = row[7]\n",
    "            month = row[8]\n",
    "            day_of_week = row[9]\n",
    "            duration = int(row[10])\n",
    "            campaign = int(row[11])\n",
    "            pdays = int(row[12])\n",
    "            previous = int(row[13])\n",
    "            poutcome = row[14]\n",
    "            emp_var_rate = float(row[15])\n",
    "            cons_price_idx = float(row[16])\n",
    "            cons_conf_idx = float(row[17])\n",
    "            euribor3m = float(row[18])\n",
    "            nr_employed = float(row[19])\n",
    "            y = bool(row[20])\n",
    "            \n",
    "            #create new data based on the data types\n",
    "            data.append([age, job, marital, education, default, housing, loan, contact, month, day_of_week, duration, \n",
    "                        campaign, pdays, previous, poutcome, emp_var_rate, cons_price_idx, cons_conf_idx, euribor3m,\n",
    "                        nr_employed, y])\n",
    "            \n",
    "            #create new csv\n",
    "            csv_writer.writerow(row)\n",
    "    \n",
    "num_of_rows = bank_info.line_num #number of rows in the dataset\n",
    "print(header)\n",
    "print(data[1])\n",
    "print(\"number of rows: %d\" %(num_of_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points: 0, 411\n",
      "Length of test set & training set: 411, 3707\n"
     ]
    }
   ],
   "source": [
    "# Define testset and trainingset\n",
    "K = 10 #number of fold for cross validation\n",
    "range = math.ceil(len(data)/K)\n",
    "iteration = 1\n",
    "\n",
    "starting_point = (iteration-1)*range\n",
    "end_point = iteration*range-1\n",
    "print(\"points: %d, %d\" %(starting_point, end_point))\n",
    "\n",
    "test_set = data[starting_point:end_point]\n",
    "training_set = data[end_point+1:len(data)]\n",
    "print(\"Length of test set & training set: %d, %d\" %(len(test_set), len(training_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrophy (data, col_attr, attr, target)\n",
    "    if attribute = null:\n",
    "        num_of_true = target.count(True)\n",
    "        num_of_false = target.count(False)\n",
    "    else:\n",
    "        attr_idx1 = np.where(data[col_attr]=='attr')\n",
    "        num_of_true = target[attr_idx].count(True)\n",
    "        num_of_false = target.count(False)\n",
    "return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.2'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test area\n",
    "import pandas\n",
    "pandas.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
